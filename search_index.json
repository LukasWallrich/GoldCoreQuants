[
["index.html", "Getting started with Quantitative Research Methods and R Overview 0.1 Further sources 0.2 Why R?", " Getting started with Quantitative Research Methods and R Lukas Wallrich Last updated: 2020-09-29 Overview This guide supports the Core Quantitative Methods Course offered by the Goldsmiths’ Graduate School. It is a living document and currently not more than a rough draft, but will grow over time - please raise any issues and suggestions here It does not follow the order of sessions in the course, instead it is ordered in a way that might allow you to see connections and hopefully helps to look things up more easily. 0.1 Further sources This guide does not aim to be comprehensive, but just to provide sufficient orientation. There are many fantastic free online resources that go further. 0.1.1 Free online books Hadley Wickham, the leading brain behind the tidyverse packages, has co-authored R for Data Science (with Garrett Grolemund). This book does not cover inferential statistics, but explains how to use R to process, describe and visualise data in line with the aproach taken in this course. The Learning statistics with R book by Danielle Navarro focuses on explaining the different statistical tests and their application in quite a lot of detail, including the underlying maths. It is written by a psychologist, and might therefore be particularly helpful for people from that discipline. 0.1.2 Paper/library books Charles Wheelan’s Naked Statistics: Stripping the Dread from the Data is an easy-to-read and entertaining New York Times bestseller that introduces statistical thinking and some key concepts without distracting details. Neil Burdess’ Starting Statistics: A short clear guide covers the basic ground with more practical and technical detail. Also have a look at the Module Guide on the learn.gold Module Page that contains further recommendations, especially with regard to research methods. 0.1.3 Other key resources The RStudio team created and collected a very helpful set of Cheatsheets that cover the key elements of various R packages - have a look here. For this course, the sheets on dplyr and ggplot2 are the most important. Stackoverflow is an online forum with a great and welcoming support community. However, make sure to use Google and their search function first to check that your question hasn’t already been answered and show what you already understand - if the same questions keep on getting asked or if the questions are very unclear, people volunteering their time to help can get a bit testy. 0.2 Why R? R is not the easiest statistical software to learn, but we are confident that it is the most useful. This article on why SPSS is dying provides some of the arguments for why that is the case. "],
["interaction-terms-in-linear-models.html", "Lecture 1 Interaction terms in linear models 1.1 Example 1: Memory and chess 1.2 Example 2: link between obesity and negative emotions in the European Social Survey 1.3 Example 3: link between working hours, income and life satisfaction", " Lecture 1 Interaction terms in linear models Watch this video for an introduction to interaction terms in linear models: The section below essentially contains the code needed for the examples in the video, with some further annotations. Before that, just one note on terminology: Generally, if two variables interact, then the effect that one has on the predictor (the regression slope) depends on the value of the other. Mathematically, that relationship is symetrical - if A interacts with B, then B interacts with A. For interpretation, we often designate one of the variables as the moderator. That just means that we are primarily interested in the effect of the other variable on the outcome and in how the moderator changes that effect. Often, demographic variables such as age or gender serve as moderators. 1.1 Example 1: Memory and chess pacman::p_load(tidyverse) The first example draws on research by Gobet &amp; Simon (1996) but uses simulated data. library(tidyverse) #Generate data (errors committed) - *roughly* based on Gobet &amp; Simon 1996 set.seed(300688) #for reproducible results ER &lt;- rnorm(50,4.9,3.5) + rnorm(50, 0, 2) NR &lt;- rnorm(50, 15.7, 4.0) + rnorm(50, 0, 2) EF &lt;- rnorm(50, 21.4, 5) + rnorm(50, 0, 2) NF &lt;- rnorm(50, 21.8, 5) + rnorm(50, 0, 2) obs &lt;- data.frame(player = &quot;expert&quot;, type = &quot;real&quot;, errors = ER, stringsAsFactors = F) %&gt;% rbind(data.frame(player = &quot;novice&quot;, type = &quot;real&quot;, errors = NR, stringsAsFactors = F)) %&gt;% rbind(data.frame(player = &quot;expert&quot;, type = &quot;fake&quot;, errors = EF, stringsAsFactors = F)) %&gt;% rbind(data.frame(player = &quot;novice&quot;, type = &quot;fake&quot;, errors = NF, stringsAsFactors = F)) %&gt;% mutate(type=factor(type), player = factor(player, levels = c(&quot;novice&quot;, &quot;expert&quot;))) #Adding the centrally mirrored condition EM &lt;- rnorm(50, 7.8, 3.5) + rnorm(50, 0, 2) NM &lt;- rnorm(50, 18, 3.5) + rnorm(50, 0, 2) obs2 &lt;- data.frame(player = &quot;expert&quot;, type = &quot;real&quot;, errors = ER, stringsAsFactors = F) %&gt;% rbind(data.frame(player = &quot;novice&quot;, type = &quot;real&quot;, errors = NR, stringsAsFactors = F)) %&gt;% rbind(data.frame(player = &quot;expert&quot;, type = &quot;fake&quot;, errors = EF, stringsAsFactors = F)) %&gt;% rbind(data.frame(player = &quot;novice&quot;, type = &quot;fake&quot;, errors = NF, stringsAsFactors = F)) %&gt;% rbind(data.frame(player = &quot;expert&quot;, type = &quot;mirrored&quot;, errors = EM, stringsAsFactors = F)) %&gt;% rbind(data.frame(player = &quot;novice&quot;, type = &quot;mirrored&quot;, errors = NM, stringsAsFactors = F)) %&gt;% mutate(type=factor(type), player = factor(player, levels = c(&quot;novice&quot;, &quot;expert&quot;))) The first model tests whether player level and position type interact. That is the case, based on the very small p-value of the interaction term. Then we use a plot to understand the nature of that interaction further - because the predictor is categorical, we use the cat_plot() function. mod &lt;- lm(errors ~ player + type + player:type, obs) summary(mod) pacman::p_load(interactions) cat_plot(mod, pred=&quot;player&quot;, modx = &quot;type&quot;, geom=&quot;line&quot;) Figure 1.1: Simple interaction plot - lines are not parallel ## ## Call: ## lm(formula = errors ~ player + type + player:type, data = obs) ## ## Residuals: ## Min 1Q Median 3Q Max ## -13.8157 -3.6637 -0.0812 3.6591 14.2213 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 21.5744 0.7398 29.164 &lt; 2e-16 *** ## playerexpert -1.2240 1.0462 -1.170 0.243 ## typereal -6.5092 1.0462 -6.222 2.91e-09 *** ## playerexpert:typereal -8.0039 1.4795 -5.410 1.83e-07 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 5.231 on 196 degrees of freedom ## Multiple R-squared: 0.5892,\tAdjusted R-squared: 0.5829 ## F-statistic: 93.69 on 3 and 196 DF, p-value: &lt; 2.2e-16 Next we consider a third condition - chess positions that are neither quite real nor entirely fake, but positions that are mirrored. With that, we get multiple dummy interaction terms. To test whether they are collectively significant, we need to use the Anova() function from the car package. mod &lt;- lm(errors ~ player + type + player:type, obs2) summary(mod) pacman::p_load(car) ## Installing package into &#39;/home/runner/work/_temp/Library&#39; ## (as &#39;lib&#39; is unspecified) ## also installing the dependencies &#39;matrixStats&#39;, &#39;RcppArmadillo&#39;, &#39;zip&#39;, &#39;SparseM&#39;, &#39;MatrixModels&#39;, &#39;conquer&#39;, &#39;sp&#39;, &#39;data.table&#39;, &#39;openxlsx&#39;, &#39;minqa&#39;, &#39;nloptr&#39;, &#39;statmod&#39;, &#39;RcppEigen&#39;, &#39;carData&#39;, &#39;abind&#39;, &#39;pbkrtest&#39;, &#39;quantreg&#39;, &#39;maptools&#39;, &#39;rio&#39;, &#39;lme4&#39; ## ## car installed car::Anova(mod, type=3) ## ## Call: ## lm(formula = errors ~ player + type + player:type, data = obs2) ## ## Residuals: ## Min 1Q Median 3Q Max ## -13.8157 -3.3006 -0.0503 3.4305 14.2213 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 21.5744 0.6881 31.354 &lt; 2e-16 *** ## playerexpert -1.2240 0.9731 -1.258 0.209 ## typemirrored -4.6796 0.9731 -4.809 2.43e-06 *** ## typereal -6.5092 0.9731 -6.689 1.13e-10 *** ## playerexpert:typemirrored -8.3088 1.3762 -6.038 4.71e-09 *** ## playerexpert:typereal -8.0039 1.3762 -5.816 1.57e-08 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 4.866 on 294 degrees of freedom ## Multiple R-squared: 0.6085,\tAdjusted R-squared: 0.6018 ## F-statistic: 91.38 on 5 and 294 DF, p-value: &lt; 2.2e-16 ## ## Anova Table (Type III tests) ## ## Response: errors ## Sum Sq Df F value Pr(&gt;F) ## (Intercept) 23272.7 1 983.0610 &lt; 2.2e-16 *** ## player 37.5 1 1.5821 0.2095 ## type 1126.9 2 23.8013 2.627e-10 *** ## player:type 1109.9 2 23.4420 3.580e-10 *** ## Residuals 6960.1 294 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 An interaction plot can then help again to understand what is going on. Here it shows that two of the three conditions are very similar. cat_plot(mod, pred=&quot;player&quot;, modx = &quot;type&quot;, geom=&quot;line&quot;) Figure 1.2: Simple interaction plot - now 2 lines are parallel 1.2 Example 2: link between obesity and negative emotions in the European Social Survey In this example, I considered the link between obesity and negative emotions in Germany in the European Social Survey 2014. Note that this relationship does not appear in the UK, which indicates that it should probably be treated as an interesting observation rather than a likely general relationship for now. ess &lt;- read_rds(url(&quot;http://empower-training.de/Gold/round7.RDS&quot;)) install.packages(&quot;psych&quot;) #Unless you have used that package before ## Installing package into &#39;/home/runner/work/_temp/Library&#39; ## (as &#39;lib&#39; is unspecified) ## also installing the dependencies &#39;tmvnsim&#39;, &#39;mnormt&#39; a &lt;- ess %&gt;% select(cldgng, fltsd, enjlf, fltlnl, wrhpp, slprl, flteeff, fltdpr) %&gt;% haven::zap_labels() %&gt;% #This is sometimes needed when SPSS files have been imported with haven and errors related to data classes appear. psych::alpha(check.keys = TRUE) ess$depr &lt;- a$scores ess$bmi &lt;- ess$weight/((ess$height/100)^2) #Filter for Germans with realistic BMI who are not underweight and reported their gender essDE &lt;- ess %&gt;% filter(bmi &lt; 60, bmi&gt;=19, gndr != &quot;No answer&quot;, cntry==&quot;DE&quot;) #Data prep for example 3 - strip unnecessary labels ess$stflife &lt;- haven::zap_labels(ess$stflife) The lm() output shows that there is a significant interaction between gender and BMI, with women having a stronger relationship between BMI and the frequency of experiencing negative emotions. This is again shown in an interaction plot - as the predictor variable is continuous, we now use the interact_plot() function. pacman::p_load(interactions) mod &lt;- lm(depr ~ bmi + gndr + bmi:gndr, essDE) summary(mod) interact_plot(mod, pred=&quot;bmi&quot;, modx = &quot;gndr&quot;) Figure 1.3: interact_plot shows different slope for men and women ## ## Call: ## lm(formula = depr ~ bmi + gndr + bmi:gndr, data = essDE) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.85559 -0.31936 -0.09363 0.25624 2.00783 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 1.486028 0.072229 20.574 &lt;2e-16 *** ## bmi 0.004674 0.002667 1.753 0.0797 . ## gndrFemale -0.091874 0.096134 -0.956 0.3393 ## bmi:gndrFemale 0.009284 0.003609 2.573 0.0101 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.438 on 2860 degrees of freedom ## (2 observations deleted due to missingness) ## Multiple R-squared: 0.037,\tAdjusted R-squared: 0.03599 ## F-statistic: 36.63 on 3 and 2860 DF, p-value: &lt; 2.2e-16 Note that ggplot2 automatically includes an interaction when fitting regression lines when a categorical variable is mappes to the colour (or linetype) aesthetic. ggplot(essDE, aes(x=bmi, y=depr, colour=gndr)) + geom_smooth(method=&quot;lm&quot;, se=FALSE) ## Warning: Removed 2 rows containing non-finite values (stat_smooth). Figure 1.4: ggplot automatically includes interaction 1.3 Example 3: link between working hours, income and life satisfaction This example considers whether working hours affect the link between income and life satisfaction - i.e. does working very long hours make income less valuable? This time, the effect appeared in the UK data in the 2014 European Social Survey - again, the question might be whether that is just an incident of spurious data mining, or whether it reveals a broader relationship. In any case, let’s have a look at the interaction. Note that * in the lm() formula is an abbreviation for + and :, so that the command below could also be written as lm(stflife ~ wkhtot + hinctnta + wkhtot:hinctnta) essUK &lt;- filter(ess, cntry == &quot;GB&quot;) mod &lt;- lm(stflife ~ wkhtot*hinctnta, essUK) summary(mod) ## ## Call: ## lm(formula = stflife ~ wkhtot * hinctnta, data = essUK) ## ## Residuals: ## Min 1Q Median 3Q Max ## -7.9013 -0.9305 0.3023 1.3331 3.6527 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 6.085338 0.242722 25.071 &lt; 2e-16 *** ## wkhtot 0.008065 0.006235 1.293 0.1960 ## hinctnta 0.238197 0.043684 5.453 5.64e-08 *** ## wkhtot:hinctnta -0.002129 0.001055 -2.019 0.0437 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 2.023 on 1810 degrees of freedom ## (450 observations deleted due to missingness) ## Multiple R-squared: 0.05154,\tAdjusted R-squared: 0.04997 ## F-statistic: 32.79 on 3 and 1810 DF, p-value: &lt; 2.2e-16 We can see that while income positively predicts life satisfaction, this effects appears to be weaker when both income andd working hours are high. However, we need to be careful with interpretation here - technically, the coefficients for income and working hours now reflect the impact of that variable when the other variable is 0, and are thus unlikely to be meaningful. Therefore, it is better to look at the interaction plot and at simple slopes analyses. Both can now be done in two ways, depending on which variable we see as the primary predictor/variable of interest. interact_plot(mod, pred=&quot;hinctnta&quot;, modx = &quot;wkhtot&quot;) Figure 1.5: Option A: strong positive effect of income, tempered by working hours interact_plot(mod, pred=&quot;wkhtot&quot;, modx = &quot;hinctnta&quot;) Figure 1.6: Option B: very different effects of working hours, depending on income Simple slopes analyses (sim_slopes()) offer similar information together with significance tests and thus help to decide which of the slopes should really be interpreted. They contain the Johnson-Neyman interval, which is the range of values of the moderator for which the predictor has a significant effect on the outcome. pacman::p_load(interactions) sim_slopes(mod, pred=&quot;hinctnta&quot;, modx = &quot;wkhtot&quot;) sim_slopes(mod, pred=&quot;wkhtot&quot;, modx = &quot;hinctnta&quot;) ## JOHNSON-NEYMAN INTERVAL ## ## When wkhtot is OUTSIDE the interval [74.17, 2622.20], the slope of hinctnta ## is p &lt; .05. ## ## Note: The range of observed values of wkhtot is [1.00, 105.00] ## ## SIMPLE SLOPES ANALYSIS ## ## Slope of hinctnta when wkhtot = 22.73 (- 1 SD): ## ## Est. S.E. t val. p ## ------ ------ -------- ------ ## 0.19 0.02 8.19 0.00 ## ## Slope of hinctnta when wkhtot = 37.72 (Mean): ## ## Est. S.E. t val. p ## ------ ------ -------- ------ ## 0.16 0.02 9.76 0.00 ## ## Slope of hinctnta when wkhtot = 52.71 (+ 1 SD): ## ## Est. S.E. t val. p ## ------ ------ -------- ------ ## 0.13 0.02 5.71 0.00 ## ## JOHNSON-NEYMAN INTERVAL ## ## When hinctnta is OUTSIDE the interval [-43.03, 7.73], the slope of wkhtot ## is p &lt; .05. ## ## Note: The range of observed values of hinctnta is [1.00, 10.00] ## ## SIMPLE SLOPES ANALYSIS ## ## Slope of wkhtot when hinctnta = 2.07 (- 1 SD): ## ## Est. S.E. t val. p ## ------ ------ -------- ------ ## 0.00 0.00 0.81 0.42 ## ## Slope of wkhtot when hinctnta = 5.05 (Mean): ## ## Est. S.E. t val. p ## ------- ------ -------- ------ ## -0.00 0.00 -0.84 0.40 ## ## Slope of wkhtot when hinctnta = 8.04 (+ 1 SD): ## ## Est. S.E. t val. p ## ------- ------ -------- ------ ## -0.01 0.00 -2.01 0.04 Finally, the johnson_neyman() function creates a plot showing the slope of one variable depending on the value of the other, while highlighting the regions of significance. This can help with an understanding of the relationship, but is not (yet?) widely used. johnson_neyman(mod, pred=&quot;wkhtot&quot;, modx = &quot;hinctnta&quot;) Figure 1.7: Johnson-Neyman plot shows regions of significance ## JOHNSON-NEYMAN INTERVAL ## ## When hinctnta is OUTSIDE the interval [-43.03, 7.73], the slope of wkhtot ## is p &lt; .05. ## ## Note: The range of observed values of hinctnta is [1.00, 10.00] "],
["chi-squared-tests-for-associations-between-categorical-variables.html", "Lecture 2 Chi-squared tests for associations between categorical variables 2.1 Tables of frequencies and proportions 2.2 The null hypothesis and the \\(\\chi^2\\) statistic 2.3 The chisq.test() function 2.4 Post-hoc tests 2.5 Effect sizes", " Lecture 2 Chi-squared tests for associations between categorical variables Watch this video for an introduction to this topic: When we want to see whether two categorical variables are associated with each other, typical linear models won’t work. Instead, we need a new way to decide whether a difference between the data we observe and that which we expect under the null-hypothesis is unlikely to occur due to chance. But before we get to that, we should look at the data. 2.1 Tables of frequencies and proportions pacman::p_load(tidyverse) With two categorical variables, the data we observe can best be shown in a frequency table - i.e. a table that shows how many observations fall into each combination of categories of the two variables. This is created with the table() function. Let’s look an example of the association between political parties and their winning candidates’ gender in the 2019 UK general election. (Note that this is based on the official statistics published by the election authorities, who registered candidate gender as a binary variable.) table(constituencies$ElectionWon, constituencies$WinnerGender) ## ## Female Male ## Con 87 278 ## Lab 104 98 ## LD 7 4 ## SNP 16 32 If there is an association between the two variables, then the proportional distribution will differ between the rows (i.e. one party would have a higher share of women than another party). To see whether that is the case, proportion tables that show shares are helpful. These can be created from the table() output with the prop.table() function. However, there are three options for proportions: are we interested in the share of each cell as a part of the total number of candidates? Or as a share of all winning candidates of a gender (i.e what share of female winning candidates are from the Conservative party)? Or rather the shares of women and men as a share of the total winning candidates of each party? In this case the latter seems most relevant and interpretable. x &lt;- table(constituencies$ElectionWon, constituencies$WinnerGender) #prop.table(x) - share of each cell as part of the total #prop.table(x, margin = 2) - share of each cell as part of the column prop.table(x, margin = 1) %&gt;% #Share of each cell as part of the row round(2) #Round to 2 decimal places ## ## Female Male ## Con 0.24 0.76 ## Lab 0.51 0.49 ## LD 0.64 0.36 ## SNP 0.33 0.67 2.2 The null hypothesis and the \\(\\chi^2\\) statistic To be able to test whether any differences between the rows or between the columns that we observe in a frequency table are statistically significant, we need to be clear on what the null hypothesis is. If two variables are statistically independent, then their distribution needs to be the same across each row and along each column. This does not mean that all cells need to have the same value, In our case, given that there are many more male than female election winners and many more Conservative MPs than MPs of any other party, we would expect the male Conservatives cell to have the highest number of observations if there was no relationship between party and winning candidates’ gender, i.e. if the null hypothesis was true. The expected number of observations in each cell under the null hypothesis can be calculated as the share of its row entire row of the total observations (e.g., the total share of female candidates) * the share of its column of the total (e.g., the total share of Labour candidates) * the total number of observations. Based on that logic, the expected number of observations per cell would be the following. ## constituencies$WinnerGender ## constituencies$ElectionWon Female Male ## Con 125 240 ## Lab 69 133 ## LD 4 7 ## SNP 16 32 Once we know what to expect under the null-hypothesis, we need a way to see how far our observed data diverges from that. The \\(\\chi^2\\) (chi-squared) test statistic provides a way of measuring that distance in a way that is independent of our sample size and therefore comparable across studies. It is calculated as follows, where O is the observed number of cases per cell of the frequency table and E is the expected number under the null-hypothesis: \\[\\chi^2=\\sum\\frac{(O-E)^2}E\\] In R, easiest way to calculate it and test whether the distance of the observed distribution from the null distribution is statistically significant is to use the chisq.test() function. 2.3 The chisq.test() function As a simple fictional example, we might be interested in whether Scottish and British people differ in their preference for tea versus coffee. If we ask 100 people, we might observe the following distribution: table(prefData$nationality, prefData$preference) ## ## Coffee Tea ## English 45 95 ## Scottish 30 30 To calculate the distance from distribution expected if there was no association between nationality and tea preference, we use the chisq.test() function. That also gives us an associated p-value. chisq.test(prefData$nationality, prefData$preference, correct = F) ## ## Pearson&#39;s Chi-squared test ## ## data: prefData$nationality and prefData$preference ## X-squared = 5.7143, df = 1, p-value = 0.01683 In this case, we would conclude that there is a statistically significant difference, with English people preferring tea more frequently than Scottish people do, \\(\\chi^2\\)(1) = 4.98, p = .016. 2.3.1 Dealing with small samples When testing the significance of \\(\\chi^2\\)-values, the calculated values are compared to a continuous distribution. When you have a small sample, however, your possible \\(\\chi^2\\)-values cannot be continous; rather, a single observation shifting from one cell to another would be associated with a substantial jump in the \\(\\chi^2\\) statistic. This can make the normal p-values far too low in such cases, and therefore lead to Type I errors (false positives). It is often recommended that \\(\\chi^2\\) should not be used with samples where the expected frequency in more than 20% of the cells is less than 5. In a 2x2 table (i.e when each of the two variables has only two possible categories), the Yates correction can be used to reduce the \\(\\chi^2\\)-value and therefore make the test more conservative (R does that by default in chisq.test(), but it can be turned off by setting correct = FALSE). However, this sometimes goes too far, so my recommendation is to simulate p-values for any samples where you have cells with low expected frequencies (say less than 20 expected cases in the smallest cell). You can do that by setting simulate.p.value = TRUE in the function call. Note that like any simulation, this is based on random number generation, so that set.seed() should be used with a fixed number of your choice to ensure that the results can be reproduced. If we were to rerun the example above with a smaller sample but more extreme differences, we can compare the three possible methods of calculating \\(\\chi^2\\). To see how small the smallest expected value is, we can look at the expected element of the output of the chisq.test() function. table(prefDataSmall$nationality, prefDataSmall$preference) chisq.test(prefDataSmall$nationality, prefDataSmall$preference, correct = F) ## ## Coffee Tea ## English 12 30 ## Scottish 10 8 ## ## Pearson&#39;s Chi-squared test ## ## data: prefDataSmall$nationality and prefDataSmall$preference ## X-squared = 3.9508, df = 1, p-value = 0.04685 It looks like the difference is significant. However, we should consider how small the smallest expected cell count is, to decide whether we need to adjust our way of testing significance. For that, we can look at the expected element of the output of the chisq.test() function. chisq.test(prefDataSmall$nationality, prefDataSmall$preference, correct = F)$expected ## prefDataSmall$preference ## prefDataSmall$nationality Coffee Tea ## English 15.4 26.6 ## Scottish 6.6 11.4 With fewer than 7 expected cases of Scottish coffee drinkers, the standard \\(\\chi^2\\) significance test is not reliable. Therefore, we either need to use the correction or simulation. Given that the simulation is based on random numbers, we should use the set.seed() function to initialise the random number generator - that makes sure that the results are reproducible. set.seed(300688) chisq.test(prefDataSmall$nationality, prefDataSmall$preference, correct = T) chisq.test(prefDataSmall$nationality, prefDataSmall$preference, simulate.p.value = T) ## ## Pearson&#39;s Chi-squared test with Yates&#39; continuity correction ## ## data: prefDataSmall$nationality and prefDataSmall$preference ## X-squared = 2.8742, df = 1, p-value = 0.09001 ## ## ## Pearson&#39;s Chi-squared test with simulated p-value (based on 2000 ## replicates) ## ## data: prefDataSmall$nationality and prefDataSmall$preference ## X-squared = 3.9508, df = NA, p-value = 0.07496 These other two methods agree that caution is needed. Usually, the simulated p-value will be a bit lower and a bit more accurate than the result of the Yates’ continuity correction, so I would report that the data shows a trend towards a greater preference for tea among English respondents that falls short of the conventional standard of statistical significance, with \\(\\chi^2\\) = 3.95, p = .075 (based on 2000 Monte Carlo simulations). 2.4 Post-hoc tests \\(\\chi^2\\)-tests can be used to test for an association between variables with many different levels, such as music preferences or political parties. In that case, a significant result only tells us that at least one of the cell counts is significantly different from the expectation under the null-hypothesis. To get more details, post-hoc tests would be needed. To go back to the example at the start, let’s test whether the winning candidates’ gender differed significantly between the major UK parties in the 2019 General Election. It certainly looks that way from the proportions table, and the chisq.test() agrees prop.table(x, margin = 1) %&gt;% #Share of each cell as part of the row round(2) #Round to 2 decimal places chisq.test(constituencies$ElectionWon, constituencies$WinnerGender, simulate.p.value = TRUE) ## ## Female Male ## Con 0.24 0.76 ## Lab 0.51 0.49 ## LD 0.64 0.36 ## SNP 0.33 0.67 ## ## Pearson&#39;s Chi-squared test with simulated p-value (based on 2000 ## replicates) ## ## data: constituencies$ElectionWon and constituencies$WinnerGender ## X-squared = 48.504, df = NA, p-value = 0.0004998 However, this does not allow us to answer questions about any specific parties. For that, we need post-hoc tests. The most common tests compare each cell to its expected value under the null-hypothesis, but other tests are possible. For instance, you might be more interested to compare parties to each other rather than to this expected (average) value. For that, you would need to filter your data and run multiple chisq.tests. To compare each cell to the expected value, we can use the chisq.posthoc.test package. This package contains the chisq.posthoc.test() function that takes a table as the input and computes standardised residuals (i.e. distances) and p-values for each cell. To avoid an inflated error rate, it can correct for multiple comparisons; by default the Bonferroni correction is used. pacman::p_load(chisq.posthoc.test) ## Installing package into &#39;/home/runner/work/_temp/Library&#39; ## (as &#39;lib&#39; is unspecified) ## ## chisq.posthoc.test installed table(constituencies$ElectionWon, constituencies$WinnerGender) %&gt;% chisq.posthoc.test(simulate.p.value = TRUE, method = &quot;bonferroni&quot;) ## Dimension Value Female Male ## 1 Con Residuals -6.4559388 6.4559388 ## 2 Con p values 0.0000000 0.0000000 ## 3 Lab Residuals 6.2985557 -6.2985557 ## 4 Lab p values 0.0000000 0.0000000 ## 5 LD Residuals 2.0776181 -2.0776181 ## 6 LD p values 0.3019560 0.3019560 ## 7 SNP Residuals -0.1295052 0.1295052 ## 8 SNP p values 1.0000000 1.0000000 In this table, the p-values can tell us which party/gender combinations differ significantly from the expectation under the null-hypothesis, while the sign of the residuals indicates the direction of the effect. Thus we can see that the Conservatives had significantly fewer male winning candidates while Labour had significantly more. A note on statistical power and the importance of thinking about corrections: This approach to running post-hoc tests runs one test per cell. In this situation with 2 genders and 4 parties, we have 8 cells, so that the Bonferroni correction multiplies each p-value by 8, which makes it relatively hard to detect effects. However, as should be clear from the table, in cases where one variable has only two levels, half of the tests are redundant. If we know that the Conservatives have significantly fewer female winners, it follows necessarily that they have significantly more male winners. p-values in each row are identical, and the residuals are symmetric. Therefore, we should only count half of the tests, and multiply p-values by 4 rather than 8. The general point is that it is essential to check how many tests a post-hoc functions counts in adjusting p-values by comparing the p-values reported when the adjustment parameter is set to “none” to those reported with “bonferroni” correction. Then make sure that you understand where that number comes from and that it makes sense in your situation. 2.5 Effect sizes As always, finding that the variables are related to a statistically significant degree is only the first step, and you also want to report the strength of the relationship. Clear proportion tables are essential here, and then there are two options to sum up the strength of relationships into a single number: Cramer’s V as a standardised measure of the strength of an association between two categorical variables, and the Odds Ratio of being in one cell rather than another. Cramer’s V describes a full table, and is scaled from 0 (no relationship) to 1 (one variable is entirely predictable by the other). It is often recommended that one should be weary of values greater than .5, as that suggests that the two variables might be redundant. Many packages offer functions to calculate Cramer’s V, including the effectsize package that allows us to calculate it based on the \\(\\chi^2\\)-value, the sample size, and the number of levels of each variable. pacman::p_load(effectsize) chisq_to_cramers_v(chisq = 48.5, n = 626, nrow=4, ncol=2) ## Cramer&#39;s V | 1e+02% CI ## ------------------------- ## 0.28 | [0.19, 0.35] While this is a helpful statistic to compare effect strengths across multiple tests, it does not have an intuitive interpretation. Here, Odds Ratios might help. They can only be calculated for 2x2 tables, for instance for the fictional example regarding tea and coffee preferences. ## ## Coffee Tea ## English 45 95 ## Scottish 30 30 Here an Odds Ratio would state how much more likely it is to get a tea afficionado if we ask an English rather than a Scottish person. Odds are the ratio of the frequency of specified outcomes over the frequency of other outcomes. For instance, the odds of it being Sunday on a random day are 1 to 6. In this case, the odds for getting a tea afficionado when picking out an English person would be 95:45, while they would be 30:30 for a Scottish person. Thus the odds ratio would be \\[OR = \\frac{\\frac{95}{45}}{\\frac{30}{30}}=2.1\\] so that I would be 2.1x more likely to get a tea afficionado rather than a coffee afficionado when picking out an English person from this sample than a Scottish person, 2.1x more likely to get a coffee afficionado rather than a tea afficionado when picking out a Scottish person rather than an English person from this sample, 2.1x more likely to have an English person in front of me when I encounter a tea afficionado from this sample, and 2.1x more likely to have a Scottish person in front of me when I encounter a coffee afficionado from this sample. All of these statements should be easier to interpret than a Cramer’s V index of .17 (which happens to be the value of this sample). Of course you should pick which one of the ways of framing the relationship is the best answer to the question at hand, rather than reporting the same information multiple times. "],
["test-pls-ignore-cq.html", "Lecture 3 Test (pls ignore - CQ)", " Lecture 3 Test (pls ignore - CQ) library(dplyr) ## ## Attaching package: &#39;dplyr&#39; ## The following objects are masked from &#39;package:stats&#39;: ## ## filter, lag ## The following objects are masked from &#39;package:base&#39;: ## ## intersect, setdiff, setequal, union mtcars %&gt;% group_by(cyl) %&gt;% summarise(mean(mpg)) ## `summarise()` ungrouping output (override with `.groups` argument) sessionInfo() ## # A tibble: 3 x 2 ## cyl `mean(mpg)` ## &lt;dbl&gt; &lt;dbl&gt; ## 1 4 26.7 ## 2 6 19.7 ## 3 8 15.1 ## R version 4.0.2 (2020-06-22) ## Platform: x86_64-pc-linux-gnu (64-bit) ## Running under: Ubuntu 18.04.5 LTS ## ## Matrix products: default ## BLAS: /usr/lib/x86_64-linux-gnu/openblas/libblas.so.3 ## LAPACK: /usr/lib/x86_64-linux-gnu/libopenblasp-r0.2.20.so ## ## locale: ## [1] LC_CTYPE=C.UTF-8 LC_NUMERIC=C LC_TIME=C.UTF-8 ## [4] LC_COLLATE=C.UTF-8 LC_MONETARY=C.UTF-8 LC_MESSAGES=C.UTF-8 ## [7] LC_PAPER=C.UTF-8 LC_NAME=C LC_ADDRESS=C ## [10] LC_TELEPHONE=C LC_MEASUREMENT=C.UTF-8 LC_IDENTIFICATION=C ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] dplyr_1.0.2 pacman_0.5.1 webex_0.9.1 ggplot2_3.3.2 ## ## loaded via a namespace (and not attached): ## [1] knitr_1.30 magrittr_1.5 tidyselect_1.1.0 munsell_0.5.0 ## [5] colorspace_1.4-1 R6_2.4.1 rlang_0.4.7 fansi_0.4.1 ## [9] stringr_1.4.0 tools_4.0.2 grid_4.0.2 gtable_0.3.0 ## [13] xfun_0.18 utf8_1.1.4 cli_2.0.2 withr_2.3.0 ## [17] htmltools_0.5.0 ellipsis_0.3.1 assertthat_0.2.1 yaml_2.2.1 ## [21] digest_0.6.25 tibble_3.0.3 lifecycle_0.2.0 crayon_1.3.4 ## [25] bookdown_0.20 purrr_0.3.4 vctrs_0.3.4 evaluate_0.14 ## [29] glue_1.4.2 rmarkdown_2.3 stringi_1.5.3 compiler_4.0.2 ## [33] pillar_1.4.6 generics_0.0.2 scales_1.1.1 pkgconfig_2.0.3 "],
["packages-and-references.html", "Lecture 4 Packages and references", " Lecture 4 Packages and references Allaire, JJ, Yihui Xie, Jonathan McPherson, Javier Luraschi, Kevin Ushey, Aron Atkins, Hadley Wickham, Joe Cheng, and Winston Chang. 2018. Rmarkdown: Dynamic Documents for R. https://CRAN.R-project.org/package=rmarkdown. Barr, Dale, and Lisa DeBruine. 2019. Webex: Create Interactive Web Exercises in R Markdown. https://github.com/psyteachr/webex. Bem, Daryl J. 2011. “Feeling the Future: Experimental Evidence for Anomalous Retroactive Influences on Cognition and Affect.” Journal of Personality and Social Psychology 100 (3): 407. Bregman, Rutger. 2020. Humankind: A Hopeful History. Bloomsbury Publishing PLC. Cialdini, Robert B. 2003. “Crafting Normative Messages to Protect the Environment.” Current Directions in Psychological Science 12 (4): 105–9. Crocker, Jennifer, Amy Canevello, and Ashley A Brown. 2017. “Social Motivation: Costs and Benefits of Selfishness and Otherishness.” Annual Review of Psychology 68: 299–325. Girme, Yuthika U. 2020. “Step Out of Line: Modeling Nonlinear Effects and Dynamics in Close-Relationships Research.” Current Directions in Psychological Science 29 (4): 351–57. Nosek, Brian A, and Timothy M Errington. 2020. “What Is Replication?” PLoS Biology 18 (3): e3000691. Open, Science Collaboration. 2015. “Psychology. Estimating the Reproducibility of Psychological Science.” Science 349 (6251): aac4716. R Core Team. 2020. R: A Language and Environment for Statistical Computing. Vienna, Austria: R Foundation for Statistical Computing. https://www.R-project.org/. Sand, Anders. 2020. “A Gentle Reminder That Mean Does Not Imply Modal Behavior: Few Are in-Group Biased in Minimal Groups.” Scandinavian Journal of Psychology. Wickham, Hadley. 2016. Ggplot2: Elegant Graphics for Data Analysis. Springer-Verlag New York. https://ggplot2.tidyverse.org. ———. 2019. Tidyverse: Easily Install and Load the Tidyverse. https://CRAN.R-project.org/package=tidyverse. Wickham, Hadley, Mara Averick, Jennifer Bryan, Winston Chang, Lucy D’Agostino McGowan, Romain François, Garrett Grolemund, et al. 2019. “Welcome to the tidyverse.” Journal of Open Source Software 4 (43): 1686. https://doi.org/10.21105/joss.01686. Wickham, Hadley, Winston Chang, Lionel Henry, Thomas Lin Pedersen, Kohske Takahashi, Claus Wilke, Kara Woo, Hiroaki Yutani, and Dewey Dunnington. 2020. Ggplot2: Create Elegant Data Visualisations Using the Grammar of Graphics. https://CRAN.R-project.org/package=ggplot2. Xie, Yihui. 2015. Dynamic Documents with R and Knitr. 2nd ed. Boca Raton, Florida: Chapman; Hall/CRC. http://yihui.name/knitr/. ———. 2016. Bookdown: Authoring Books and Technical Documents with R Markdown. Boca Raton, Florida: Chapman; Hall/CRC. https://github.com/rstudio/bookdown. ———. 2020. Bookdown: Authoring Books and Technical Documents with R Markdown. https://github.com/rstudio/bookdown. "],
["two-more-pipes.html", "Seminar 1 Two more pipes A.1 Expanding the tidyverse: the exposition pipe (%$%) A.2 A somewhat risky time-saver: the assignment pipe (%&lt;&gt;%)", " Seminar 1 Two more pipes If you are clear on the pipe operator %&gt;% then two more pipes can help you save some typing and write more efficient code. However, neither are critical for this course. All of them require that you load the magrittr package explicitly - it is installed as part of the tidyverse, but not loaded. library(tidyverse) library(magrittr) #Example data constituencies &lt;- read_csv(url(&quot;http://empower-training.de/Gold/ConstituencyData2019.csv&quot;), col_types = &quot;_cfddddfffddddfffdfdddd&quot;) A.1 Expanding the tidyverse: the exposition pipe (%$%) Inside dplyr pipes, you do not need to use the $ to access variables within the dataframe. However, that does not work in some base-R functions such as cor.test(). For them, %$% can expose the variables in a dataframe temporarily (until the end of that command) so that they can be accessed as if they were separate variables in your environment. #Normal code cor.test(constituencies$MedianAge, constituencies$ElectionConShare) #With the exposition pipe constituencies %$% cor.test(MedianAge, ElectionConShare) ## ## Pearson&#39;s product-moment correlation ## ## data: constituencies$MedianAge and constituencies$ElectionConShare ## t = 16.454, df = 648, p-value &lt; 2.2e-16 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## 0.4862318 0.5949037 ## sample estimates: ## cor ## 0.542836 ## ## ## Pearson&#39;s product-moment correlation ## ## data: MedianAge and ElectionConShare ## t = 16.454, df = 648, p-value &lt; 2.2e-16 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## 0.4862318 0.5949037 ## sample estimates: ## cor ## 0.542836 Clearly in this case, the difference is slight but you might find it more readable as well. In other cases, this can spare you from having to save a filtered dataset or otherwise processed dataset into a new variable that you are only using once. constituencies %&gt;% filter(ContType == &quot;County&quot;) %$% cor.test(MedianAge, ElectionConShare) ## ## Pearson&#39;s product-moment correlation ## ## data: MedianAge and ElectionConShare ## t = 7.4961, df = 366, p-value = 5.003e-13 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## 0.2727644 0.4502600 ## sample estimates: ## cor ## 0.3648222 A.2 A somewhat risky time-saver: the assignment pipe (%&lt;&gt;%) Quite often, we want to edit an element in place, which leads to some repetition as you need to specify that you want to put it into the pipe and then save it back in place. #Normal code constituencies &lt;- constituencies %&gt;% filter(ConstituencyName != &quot;Chorley&quot;) #With assignment pipe constituencies %&lt;&gt;% filter(ConstituencyName != &quot;Chorley&quot;) The assignment pipe here takes constituencies, puts it into the pipeline, and takes the result at the end to save back into constituencies. It can be particularly pleasant when you want to apply a function to a single variable, but be careful not to use it accidentally - if you type %&lt;&gt;% instead of %&gt;% you will create bugs in your code that are not easy to spot. constituencies$ElectionWon %&lt;&gt;% relevel(ref=&quot;Lab&quot;) "]
]
