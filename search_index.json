[
["index.html", "Getting started with Quantitative Research Methods and R Overview 0.1 Further sources 0.2 Why R?", " Getting started with Quantitative Research Methods and R Lukas Wallrich Last updated: 2020-09-29 Overview This guide supports the Core Quantitative Methods Course offered by the Goldsmiths’ Graduate School. It is a living document and currently not more than a rough draft, but will grow over time - please raise any issues and suggestions here It does not follow the order of sessions in the course, instead it is ordered in a way that might allow you to see connections and hopefully helps to look things up more easily. 0.1 Further sources This guide does not aim to be comprehensive, but just to provide sufficient orientation. There are many fantastic free online resources that go further. 0.1.1 Free online books Hadley Wickham, the leading brain behind the tidyverse packages, has co-authored R for Data Science (with Garrett Grolemund). This book does not cover inferential statistics, but explains how to use R to process, describe and visualise data in line with the aproach taken in this course. The Learning statistics with R book by Danielle Navarro focuses on explaining the different statistical tests and their application in quite a lot of detail, including the underlying maths. It is written by a psychologist, and might therefore be particularly helpful for people from that discipline. 0.1.2 Paper/library books Charles Wheelan’s Naked Statistics: Stripping the Dread from the Data is an easy-to-read and entertaining New York Times bestseller that introduces statistical thinking and some key concepts without distracting details. Neil Burdess’ Starting Statistics: A short clear guide covers the basic ground with more practical and technical detail. Also have a look at the Module Guide on the learn.gold Module Page that contains further recommendations, especially with regard to research methods. 0.1.3 Other key resources The RStudio team created and collected a very helpful set of Cheatsheets that cover the key elements of various R packages - have a look here. For this course, the sheets on dplyr and ggplot2 are the most important. Stackoverflow is an online forum with a great and welcoming support community. However, make sure to use Google and their search function first to check that your question hasn’t already been answered and show what you already understand - if the same questions keep on getting asked or if the questions are very unclear, people volunteering their time to help can get a bit testy. 0.2 Why R? R is not the easiest statistical software to learn, but we are confident that it is the most useful. This article on why SPSS is dying provides some of the arguments for why that is the case. "],
["chi-squared-tests-for-associations-between-categorical-variables.html", "Lecture 1 Chi-squared tests for associations between categorical variables 1.1 Tables of frequencies and proportions 1.2 The null hypothesis and the \\(\\chi^2\\) statistic 1.3 The chisq.test() function 1.4 Post-hoc tests 1.5 Effect sizes", " Lecture 1 Chi-squared tests for associations between categorical variables Watch this video for an introduction to this topic: When we want to see whether two categorical variables are associated with each other, typical linear models won’t work. Instead, we need a new way to decide whether a difference between the data we observe and that which we expect under the null-hypothesis is unlikely to occur due to chance. But before we get to that, we should look at the data. 1.1 Tables of frequencies and proportions pacman::p_load(tidyverse) With two categorical variables, the data we observe can best be shown in a frequency table - i.e. a table that shows how many observations fall into each combination of categories of the two variables. This is created with the table() function. Let’s look an example of the association between political parties and their winning candidates’ gender in the 2019 UK general election. (Note that this is based on the official statistics published by the election authorities, who registered candidate gender as a binary variable.) table(constituencies$ElectionWon, constituencies$WinnerGender) ## ## Female Male ## Con 87 278 ## Lab 104 98 ## LD 7 4 ## SNP 16 32 If there is an association between the two variables, then the proportional distribution will differ between the rows (i.e. one party would have a higher share of women than another party). To see whether that is the case, proportion tables that show shares are helpful. These can be created from the table() output with the prop.table() function. However, there are three options for proportions: are we interested in the share of each cell as a part of the total number of candidates? Or as a share of all winning candidates of a gender (i.e what share of female winning candidates are from the Conservative party)? Or rather the shares of women and men as a share of the total winning candidates of each party? In this case the latter seems most relevant and interpretable. x &lt;- table(constituencies$ElectionWon, constituencies$WinnerGender) #prop.table(x) - share of each cell as part of the total #prop.table(x, margin = 2) - share of each cell as part of the column prop.table(x, margin = 1) %&gt;% #Share of each cell as part of the row round(2) #Round to 2 decimal places ## ## Female Male ## Con 0.24 0.76 ## Lab 0.51 0.49 ## LD 0.64 0.36 ## SNP 0.33 0.67 1.2 The null hypothesis and the \\(\\chi^2\\) statistic To be able to test whether any differences between the rows or between the columns that we observe in a frequency table are statistically significant, we need to be clear on what the null hypothesis is. If two variables are statistically independent, then their distribution needs to be the same across each row and along each column. This does not mean that all cells need to have the same value, In our case, given that there are many more male than female election winners and many more Conservative MPs than MPs of any other party, we would expect the male Conservatives cell to have the highest number of observations if there was no relationship between party and winning candidates’ gender, i.e. if the null hypothesis was true. The expected number of observations in each cell under the null hypothesis can be calculated as the share of its row entire row of the total observations (e.g., the total share of female candidates) * the share of its column of the total (e.g., the total share of Labour candidates) * the total number of observations. Based on that logic, the expected number of observations per cell would be the following. ## constituencies$WinnerGender ## constituencies$ElectionWon Female Male ## Con 125 240 ## Lab 69 133 ## LD 4 7 ## SNP 16 32 Once we know what to expect under the null-hypothesis, we need a way to see how far our observed data diverges from that. The \\(\\chi^2\\) (chi-squared) test statistic provides a way of measuring that distance in a way that is independent of our sample size and therefore comparable across studies. It is calculated as follows, where O is the observed number of cases per cell of the frequency table and E is the expected number under the null-hypothesis: \\[\\chi^2=\\sum\\frac{(O-E)^2}E\\] In R, easiest way to calculate it and test whether the distance of the observed distribution from the null distribution is statistically significant is to use the chisq.test() function. 1.3 The chisq.test() function As a simple fictional example, we might be interested in whether Scottish and British people differ in their preference for tea versus coffee. If we ask 100 people, we might observe the following distribution: table(prefData$nationality, prefData$preference) ## ## Coffee Tea ## English 45 95 ## Scottish 30 30 To calculate the distance from distribution expected if there was no association between nationality and tea preference, we use the chisq.test() function. That also gives us an associated p-value. chisq.test(prefData$nationality, prefData$preference, correct = F) ## ## Pearson&#39;s Chi-squared test ## ## data: prefData$nationality and prefData$preference ## X-squared = 5.7143, df = 1, p-value = 0.01683 In this case, we would conclude that there is a statistically significant difference, with English people preferring tea more frequently than Scottish people do, \\(\\chi^2\\)(1) = 4.98, p = .016. 1.3.1 Dealing with small samples When testing the significance of \\(\\chi^2\\)-values, the calculated values are compared to a continuous distribution. When you have a small sample, however, your possible \\(\\chi^2\\)-values cannot be continous; rather, a single observation shifting from one cell to another would be associated with a substantial jump in the \\(\\chi^2\\) statistic. This can make the normal p-values far too low in such cases, and therefore lead to Type I errors (false positives). It is often recommended that \\(\\chi^2\\) should not be used with samples where the expected frequency in more than 20% of the cells is less than 5. In a 2x2 table (i.e when each of the two variables has only two possible categories), the Yates correction can be used to reduce the \\(\\chi^2\\)-value and therefore make the test more conservative (R does that by default in chisq.test(), but it can be turned off by setting correct = FALSE). However, this sometimes goes too far, so my recommendation is to simulate p-values for any samples where you have cells with low expected frequencies (say less than 20 expected cases in the smallest cell). You can do that by setting simulate.p.value = TRUE in the function call. Note that like any simulation, this is based on random number generation, so that set.seed() should be used with a fixed number of your choice to ensure that the results can be reproduced. If we were to rerun the example above with a smaller sample but more extreme differences, we can compare the three possible methods of calculating \\(\\chi^2\\). To see how small the smallest expected value is, we can look at the expected element of the output of the chisq.test() function. table(prefDataSmall$nationality, prefDataSmall$preference) chisq.test(prefDataSmall$nationality, prefDataSmall$preference, correct = F) ## ## Coffee Tea ## English 12 30 ## Scottish 10 8 ## ## Pearson&#39;s Chi-squared test ## ## data: prefDataSmall$nationality and prefDataSmall$preference ## X-squared = 3.9508, df = 1, p-value = 0.04685 It looks like the difference is significant. However, we should consider how small the smallest expected cell count is, to decide whether we need to adjust our way of testing significance. For that, we can look at the expected element of the output of the chisq.test() function. chisq.test(prefDataSmall$nationality, prefDataSmall$preference, correct = F)$expected ## prefDataSmall$preference ## prefDataSmall$nationality Coffee Tea ## English 15.4 26.6 ## Scottish 6.6 11.4 With fewer than 7 expected cases of Scottish coffee drinkers, the standard \\(\\chi^2\\) significance test is not reliable. Therefore, we either need to use the correction or simulation. Given that the simulation is based on random numbers, we should use the set.seed() function to initialise the random number generator - that makes sure that the results are reproducible. set.seed(300688) chisq.test(prefDataSmall$nationality, prefDataSmall$preference, correct = T) chisq.test(prefDataSmall$nationality, prefDataSmall$preference, simulate.p.value = T) ## ## Pearson&#39;s Chi-squared test with Yates&#39; continuity correction ## ## data: prefDataSmall$nationality and prefDataSmall$preference ## X-squared = 2.8742, df = 1, p-value = 0.09001 ## ## ## Pearson&#39;s Chi-squared test with simulated p-value (based on 2000 ## replicates) ## ## data: prefDataSmall$nationality and prefDataSmall$preference ## X-squared = 3.9508, df = NA, p-value = 0.07496 These other two methods agree that caution is needed. Usually, the simulated p-value will be a bit lower and a bit more accurate than the result of the Yates’ continuity correction, so I would report that the data shows a trend towards a greater preference for tea among English respondents that falls short of the conventional standard of statistical significance, with \\(\\chi^2\\) = 3.95, p = .075 (based on 2000 Monte Carlo simulations). 1.4 Post-hoc tests \\(\\chi^2\\)-tests can be used to test for an association between variables with many different levels, such as music preferences or political parties. In that case, a significant result only tells us that at least one of the cell counts is significantly different from the expectation under the null-hypothesis. To get more details, post-hoc tests would be needed. To go back to the example at the start, let’s test whether the winning candidates’ gender differed significantly between the major UK parties in the 2019 General Election. It certainly looks that way from the proportions table, and the chisq.test() agrees prop.table(x, margin = 1) %&gt;% #Share of each cell as part of the row round(2) #Round to 2 decimal places chisq.test(constituencies$ElectionWon, constituencies$WinnerGender, simulate.p.value = TRUE) ## ## Female Male ## Con 0.24 0.76 ## Lab 0.51 0.49 ## LD 0.64 0.36 ## SNP 0.33 0.67 ## ## Pearson&#39;s Chi-squared test with simulated p-value (based on 2000 ## replicates) ## ## data: constituencies$ElectionWon and constituencies$WinnerGender ## X-squared = 48.504, df = NA, p-value = 0.0004998 However, this does not allow us to answer questions about any specific parties. For that, we need post-hoc tests. The most common tests compare each cell to its expected value under the null-hypothesis, but other tests are possible. For instance, you might be more interested to compare parties to each other rather than to this expected (average) value. For that, you would need to filter your data and run multiple chisq.tests. To compare each cell to the expected value, we can use the chisq.posthoc.test package. This package contains the chisq.posthoc.test() function that takes a table as the input and computes standardised residuals (i.e. distances) and p-values for each cell. To avoid an inflated error rate, it can correct for multiple comparisons; by default the Bonferroni correction is used. pacman::p_load(chisq.posthoc.test) ## Installing package into &#39;/home/runner/work/_temp/Library&#39; ## (as &#39;lib&#39; is unspecified) ## ## chisq.posthoc.test installed table(constituencies$ElectionWon, constituencies$WinnerGender) %&gt;% chisq.posthoc.test(simulate.p.value = TRUE, method = &quot;bonferroni&quot;) ## Dimension Value Female Male ## 1 Con Residuals -6.4559388 6.4559388 ## 2 Con p values 0.0000000 0.0000000 ## 3 Lab Residuals 6.2985557 -6.2985557 ## 4 Lab p values 0.0000000 0.0000000 ## 5 LD Residuals 2.0776181 -2.0776181 ## 6 LD p values 0.3019560 0.3019560 ## 7 SNP Residuals -0.1295052 0.1295052 ## 8 SNP p values 1.0000000 1.0000000 In this table, the p-values can tell us which party/gender combinations differ significantly from the expectation under the null-hypothesis, while the sign of the residuals indicates the direction of the effect. Thus we can see that the Conservatives had significantly fewer male winning candidates while Labour had significantly more. A note on statistical power and the importance of thinking about corrections: This approach to running post-hoc tests runs one test per cell. In this situation with 2 genders and 4 parties, we have 8 cells, so that the Bonferroni correction multiplies each p-value by 8, which makes it relatively hard to detect effects. However, as should be clear from the table, in cases where one variable has only two levels, half of the tests are redundant. If we know that the Conservatives have significantly fewer female winners, it follows necessarily that they have significantly more male winners. p-values in each row are identical, and the residuals are symmetric. Therefore, we should only count half of the tests, and multiply p-values by 4 rather than 8. The general point is that it is essential to check how many tests a post-hoc functions counts in adjusting p-values by comparing the p-values reported when the adjustment parameter is set to “none” to those reported with “bonferroni” correction. Then make sure that you understand where that number comes from and that it makes sense in your situation. 1.5 Effect sizes As always, finding that the variables are related to a statistically significant degree is only the first step, and you also want to report the strength of the relationship. Clear proportion tables are essential here, and then there are two options to sum up the strength of relationships into a single number: Cramer’s V as a standardised measure of the strength of an association between two categorical variables, and the Odds Ratio of being in one cell rather than another. Cramer’s V describes a full table, and is scaled from 0 (no relationship) to 1 (one variable is entirely predictable by the other). It is often recommended that one should be weary of values greater than .5, as that suggests that the two variables might be redundant. Many packages offer functions to calculate Cramer’s V, including the effectsize package that allows us to calculate it based on the \\(\\chi^2\\)-value, the sample size, and the number of levels of each variable. pacman::p_load(effectsize) chisq_to_cramers_v(chisq = 48.5, n = 626, nrow=4, ncol=2) ## Cramer&#39;s V | 1e+02% CI ## ------------------------- ## 0.28 | [0.19, 0.35] While this is a helpful statistic to compare effect strengths across multiple tests, it does not have an intuitive interpretation. Here, Odds Ratios might help. They can only be calculated for 2x2 tables, for instance for the fictional example regarding tea and coffee preferences. ## ## Coffee Tea ## English 45 95 ## Scottish 30 30 Here an Odds Ratio would state how much more likely it is to get a tea afficionado if we ask an English rather than a Scottish person. Odds are the ratio of the frequency of specified outcomes over the frequency of other outcomes. For instance, the odds of it being Sunday on a random day are 1 to 6. In this case, the odds for getting a tea afficionado when picking out an English person would be 95:45, while they would be 30:30 for a Scottish person. Thus the odds ratio would be \\[OR = \\frac{\\frac{95}{45}}{\\frac{30}{30}}=2.1\\] so that I would be 2.1x more likely to get a tea afficionado rather than a coffee afficionado when picking out an English person from this sample than a Scottish person, 2.1x more likely to get a coffee afficionado rather than a tea afficionado when picking out a Scottish person rather than an English person from this sample, 2.1x more likely to have an English person in front of me when I encounter a tea afficionado from this sample, and 2.1x more likely to have a Scottish person in front of me when I encounter a coffee afficionado from this sample. All of these statements should be easier to interpret than a Cramer’s V index of .17 (which happens to be the value of this sample). Of course you should pick which one of the ways of framing the relationship is the best answer to the question at hand, rather than reporting the same information multiple times. "],
["test-pls-ignore-cq.html", "Lecture 2 Test (pls ignore - CQ)", " Lecture 2 Test (pls ignore - CQ) library(dplyr) ## ## Attaching package: &#39;dplyr&#39; ## The following objects are masked from &#39;package:stats&#39;: ## ## filter, lag ## The following objects are masked from &#39;package:base&#39;: ## ## intersect, setdiff, setequal, union mtcars %&gt;% group_by(cyl) %&gt;% summarise(mean(mpg)) ## `summarise()` ungrouping output (override with `.groups` argument) sessionInfo() ## # A tibble: 3 x 2 ## cyl `mean(mpg)` ## &lt;dbl&gt; &lt;dbl&gt; ## 1 4 26.7 ## 2 6 19.7 ## 3 8 15.1 ## R version 4.0.2 (2020-06-22) ## Platform: x86_64-pc-linux-gnu (64-bit) ## Running under: Ubuntu 18.04.5 LTS ## ## Matrix products: default ## BLAS: /usr/lib/x86_64-linux-gnu/openblas/libblas.so.3 ## LAPACK: /usr/lib/x86_64-linux-gnu/libopenblasp-r0.2.20.so ## ## locale: ## [1] LC_CTYPE=C.UTF-8 LC_NUMERIC=C LC_TIME=C.UTF-8 ## [4] LC_COLLATE=C.UTF-8 LC_MONETARY=C.UTF-8 LC_MESSAGES=C.UTF-8 ## [7] LC_PAPER=C.UTF-8 LC_NAME=C LC_ADDRESS=C ## [10] LC_TELEPHONE=C LC_MEASUREMENT=C.UTF-8 LC_IDENTIFICATION=C ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] dplyr_1.0.2 pacman_0.5.1 webex_0.9.1 ggplot2_3.3.2 ## ## loaded via a namespace (and not attached): ## [1] knitr_1.30 magrittr_1.5 tidyselect_1.1.0 munsell_0.5.0 ## [5] colorspace_1.4-1 R6_2.4.1 rlang_0.4.7 fansi_0.4.1 ## [9] stringr_1.4.0 tools_4.0.2 grid_4.0.2 gtable_0.3.0 ## [13] xfun_0.18 utf8_1.1.4 cli_2.0.2 withr_2.3.0 ## [17] htmltools_0.5.0 ellipsis_0.3.1 assertthat_0.2.1 yaml_2.2.1 ## [21] digest_0.6.25 tibble_3.0.3 lifecycle_0.2.0 crayon_1.3.4 ## [25] bookdown_0.20 purrr_0.3.4 vctrs_0.3.4 evaluate_0.14 ## [29] glue_1.4.2 rmarkdown_2.3 stringi_1.5.3 compiler_4.0.2 ## [33] pillar_1.4.6 generics_0.0.2 scales_1.1.1 pkgconfig_2.0.3 "],
["packages-and-references.html", "Lecture 3 Packages and references", " Lecture 3 Packages and references Allaire, JJ, Yihui Xie, Jonathan McPherson, Javier Luraschi, Kevin Ushey, Aron Atkins, Hadley Wickham, Joe Cheng, and Winston Chang. 2018. Rmarkdown: Dynamic Documents for R. https://CRAN.R-project.org/package=rmarkdown. Barr, Dale, and Lisa DeBruine. 2019. Webex: Create Interactive Web Exercises in R Markdown. https://github.com/psyteachr/webex. Bem, Daryl J. 2011. “Feeling the Future: Experimental Evidence for Anomalous Retroactive Influences on Cognition and Affect.” Journal of Personality and Social Psychology 100 (3): 407. Bregman, Rutger. 2020. Humankind: A Hopeful History. Bloomsbury Publishing PLC. Cialdini, Robert B. 2003. “Crafting Normative Messages to Protect the Environment.” Current Directions in Psychological Science 12 (4): 105–9. Crocker, Jennifer, Amy Canevello, and Ashley A Brown. 2017. “Social Motivation: Costs and Benefits of Selfishness and Otherishness.” Annual Review of Psychology 68: 299–325. Girme, Yuthika U. 2020. “Step Out of Line: Modeling Nonlinear Effects and Dynamics in Close-Relationships Research.” Current Directions in Psychological Science 29 (4): 351–57. Nosek, Brian A, and Timothy M Errington. 2020. “What Is Replication?” PLoS Biology 18 (3): e3000691. Open, Science Collaboration. 2015. “Psychology. Estimating the Reproducibility of Psychological Science.” Science 349 (6251): aac4716. R Core Team. 2020. R: A Language and Environment for Statistical Computing. Vienna, Austria: R Foundation for Statistical Computing. https://www.R-project.org/. Sand, Anders. 2020. “A Gentle Reminder That Mean Does Not Imply Modal Behavior: Few Are in-Group Biased in Minimal Groups.” Scandinavian Journal of Psychology. Wickham, Hadley. 2016. Ggplot2: Elegant Graphics for Data Analysis. Springer-Verlag New York. https://ggplot2.tidyverse.org. ———. 2019. Tidyverse: Easily Install and Load the Tidyverse. https://CRAN.R-project.org/package=tidyverse. Wickham, Hadley, Mara Averick, Jennifer Bryan, Winston Chang, Lucy D’Agostino McGowan, Romain François, Garrett Grolemund, et al. 2019. “Welcome to the tidyverse.” Journal of Open Source Software 4 (43): 1686. https://doi.org/10.21105/joss.01686. Wickham, Hadley, Winston Chang, Lionel Henry, Thomas Lin Pedersen, Kohske Takahashi, Claus Wilke, Kara Woo, Hiroaki Yutani, and Dewey Dunnington. 2020. Ggplot2: Create Elegant Data Visualisations Using the Grammar of Graphics. https://CRAN.R-project.org/package=ggplot2. Xie, Yihui. 2015. Dynamic Documents with R and Knitr. 2nd ed. Boca Raton, Florida: Chapman; Hall/CRC. http://yihui.name/knitr/. ———. 2016. Bookdown: Authoring Books and Technical Documents with R Markdown. Boca Raton, Florida: Chapman; Hall/CRC. https://github.com/rstudio/bookdown. ———. 2020. Bookdown: Authoring Books and Technical Documents with R Markdown. https://github.com/rstudio/bookdown. "],
["two-more-pipes.html", "Seminar 1 Two more pipes A.1 Expanding the tidyverse: the exposition pipe (%$%) A.2 A somewhat risky time-saver: the assignment pipe (%&lt;&gt;%)", " Seminar 1 Two more pipes If you are clear on the pipe operator %&gt;% then two more pipes can help you save some typing and write more efficient code. However, neither are critical for this course. All of them require that you load the magrittr package explicitly - it is installed as part of the tidyverse, but not loaded. library(tidyverse) library(magrittr) #Example data constituencies &lt;- read_csv(url(&quot;http://empower-training.de/Gold/ConstituencyData2019.csv&quot;), col_types = &quot;_cfddddfffddddfffdfdddd&quot;) A.1 Expanding the tidyverse: the exposition pipe (%$%) Inside dplyr pipes, you do not need to use the $ to access variables within the dataframe. However, that does not work in some base-R functions such as cor.test(). For them, %$% can expose the variables in a dataframe temporarily (until the end of that command) so that they can be accessed as if they were separate variables in your environment. #Normal code cor.test(constituencies$MedianAge, constituencies$ElectionConShare) #With the exposition pipe constituencies %$% cor.test(MedianAge, ElectionConShare) ## ## Pearson&#39;s product-moment correlation ## ## data: constituencies$MedianAge and constituencies$ElectionConShare ## t = 16.454, df = 648, p-value &lt; 2.2e-16 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## 0.4862318 0.5949037 ## sample estimates: ## cor ## 0.542836 ## ## ## Pearson&#39;s product-moment correlation ## ## data: MedianAge and ElectionConShare ## t = 16.454, df = 648, p-value &lt; 2.2e-16 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## 0.4862318 0.5949037 ## sample estimates: ## cor ## 0.542836 Clearly in this case, the difference is slight but you might find it more readable as well. In other cases, this can spare you from having to save a filtered dataset or otherwise processed dataset into a new variable that you are only using once. constituencies %&gt;% filter(ContType == &quot;County&quot;) %$% cor.test(MedianAge, ElectionConShare) ## ## Pearson&#39;s product-moment correlation ## ## data: MedianAge and ElectionConShare ## t = 7.4961, df = 366, p-value = 5.003e-13 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## 0.2727644 0.4502600 ## sample estimates: ## cor ## 0.3648222 A.2 A somewhat risky time-saver: the assignment pipe (%&lt;&gt;%) Quite often, we want to edit an element in place, which leads to some repetition as you need to specify that you want to put it into the pipe and then save it back in place. #Normal code constituencies &lt;- constituencies %&gt;% filter(ConstituencyName != &quot;Chorley&quot;) #With assignment pipe constituencies %&lt;&gt;% filter(ConstituencyName != &quot;Chorley&quot;) The assignment pipe here takes constituencies, puts it into the pipeline, and takes the result at the end to save back into constituencies. It can be particularly pleasant when you want to apply a function to a single variable, but be careful not to use it accidentally - if you type %&lt;&gt;% instead of %&gt;% you will create bugs in your code that are not easy to spot. constituencies$ElectionWon %&lt;&gt;% relevel(ref=&quot;Lab&quot;) "]
]
